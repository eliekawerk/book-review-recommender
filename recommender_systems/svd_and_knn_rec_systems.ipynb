{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:08:50.413884Z",
     "start_time": "2020-06-03T22:08:48.891902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random\n",
    "import surprise as sur\n",
    "\n",
    "#This is the python script that I wrote that contains all the functions required to calculate the recommendations\n",
    "import recommender_functions\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have outlined the code to build the prediction matrices for both the SVD and KNNBaseline algos (fitted for the optimal parameters after gridsearching) in this notebook. To test the examples and use the functions in the recommender_funtions script, please check the basic or BaselineOnly implementations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a recommender system using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:08:51.266733Z",
     "start_time": "2020-06-03T22:08:50.459215Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/../../../df_sub.csv.gz', \n",
    "                       compression='gzip').astype({'rating':'int8', 'total_votes':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:08:51.747006Z",
     "start_time": "2020-06-03T22:08:51.295637Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('/../../../meta_df_sub.csv.gz', compression='gzip', \n",
    "                      names = ['asin', 'title', 'description', 'price', 'categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:12:28.644067Z",
     "start_time": "2020-06-03T22:12:21.546477Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load in the metadata and book review merged dataframe\n",
    "merged = pd.read_csv('/../../../merged.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data as a DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:10:21.502296Z",
     "start_time": "2020-06-03T22:10:21.173221Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prepare the data in a format required by Surprise\n",
    "reader = sur.Reader(rating_scale=(1,5))\n",
    "data = sur.Dataset.load_from_df(df[['reviewerId', 'asin','rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and compute scores for the model - (optimal cv score: 0.85787) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:10:10.597271Z",
     "start_time": "2020-06-03T22:10:10.585987Z"
    }
   },
   "outputs": [],
   "source": [
    "#Best options after gridsearching\n",
    "\n",
    "algo = sur.SVD(random_state=1,\n",
    "        biased=True,  # isolate sdasbiases\n",
    "        reg_all=0.2,  # use regularisation (the same for all)\n",
    "        n_epochs=20,  # number of epochs for stochastic gradient descent search\n",
    "        n_factors=100,  # number of factors to retain in SVD\n",
    "        lr_all=0.01\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:10:32.648802Z",
     "start_time": "2020-06-03T22:10:32.309643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246294\n",
      "27367\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data in train and test set\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "#shuffle ratings if you want\n",
    "np.random.seed(1)\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "\n",
    "#section the data into training set and test set\n",
    "threshold = int(.9 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "print(len(A_raw_ratings))\n",
    "print(len(B_raw_ratings))\n",
    "\n",
    "#make the raw ratings contain only the training set\n",
    "data.raw_ratings = A_raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:10:54.625536Z",
     "start_time": "2020-06-03T22:10:34.331331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x122c69750>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Built a trainset out the training set\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:10:59.262221Z",
     "start_time": "2020-06-03T22:10:55.611266Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score    RMSE: 0.7871\n",
      "0.7870792954940502\n"
     ]
    }
   ],
   "source": [
    "# Compute score on training set\n",
    "trainset_build = trainset.build_testset()\n",
    "predictions_train = algo.test(trainset_build)\n",
    "\n",
    "print('Training score ', end='   ')\n",
    "print(sur.accuracy.rmse(predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:11:01.451499Z",
     "start_time": "2020-06-03T22:11:00.902096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score (rated items)  RMSE: 0.8462\n",
      "0.8461879979916598\n"
     ]
    }
   ],
   "source": [
    "# Compute score on rated test set\n",
    "testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "predictions_test = algo.test(testset)\n",
    "print('Test score (rated items) ', end=' ')\n",
    "print(sur.accuracy.rmse(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the user item matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:34:16.655742Z",
     "start_time": "2020-05-17T12:34:16.647357Z"
    }
   },
   "source": [
    "We will need to the train the algo on all of the available ratings to get the most accurate readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:13:35.001636Z",
     "start_time": "2020-06-03T22:13:10.529407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score    RMSE: 0.7931\n",
      "0.7930987517491225\n"
     ]
    }
   ],
   "source": [
    "data.raw_ratings = raw_ratings\n",
    "\n",
    "#Built a trainset using the full data\n",
    "trainset_full = data.build_full_trainset()\n",
    "algo.fit(trainset_full)\n",
    "\n",
    "# Compute score on training set\n",
    "trainset_full_build = trainset_full.build_testset()\n",
    "predictions_full_train = algo.test(trainset_full_build)\n",
    "\n",
    "print('Training score ', end='   ')\n",
    "print(sur.accuracy.rmse(predictions_full_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the equation laid out in [this report](http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf) to calculate the user item matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:14:24.333483Z",
     "start_time": "2020-06-03T22:14:24.007163Z"
    }
   },
   "outputs": [],
   "source": [
    "pu = algo.pu\n",
    "qi = algo.qi\n",
    "puqi = pu.dot(qi.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:14:29.294783Z",
     "start_time": "2020-06-03T22:14:29.288479Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "2647\n",
      "100\n",
      "10982\n"
     ]
    }
   ],
   "source": [
    "#Shape of the features should match the number of factors (100), number of users and books\n",
    "print(len(pu[0]))\n",
    "print(len(pu))\n",
    "print(len(qi[0]))\n",
    "print(len(qi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:14:59.673017Z",
     "start_time": "2020-06-03T22:14:59.055920Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.089157753571024\n"
     ]
    }
   ],
   "source": [
    "#Calculating the user-item matrix\n",
    "mu = algo.default_prediction()\n",
    "print(mu)\n",
    "full_pred = mu + algo.bu.reshape(-1, 1) + algo.bi.reshape(1, -1) + puqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:15:06.390877Z",
     "start_time": "2020-06-03T22:15:06.126159Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A100NGGXRQF0AQ', 883, -0.0167047518833552),\n",
       " ('A102Z3T7NSM5KC', 336, 0.07280186097433244),\n",
       " ('A106016KSI0YQ', 1895, -0.39515800344395324),\n",
       " ('A106E1N0ZQ4D9W', 315, 0.16078289251947328),\n",
       " ('A10BZSGALQPS0V', 734, -0.20103781355281278)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain the mapping of each inner id to raw id for every user\n",
    "user_baselines=[]\n",
    "\n",
    "for user in np.unique(df.reviewerId):\n",
    "    user_baselines.append((user, trainset_full.to_inner_uid(user), algo.bu[trainset_full.to_inner_uid(user)]))\n",
    "\n",
    "user_baselines[:5]\n",
    "\n",
    "#The pu tags appear in the same order as this as the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T16:03:43.782211Z",
     "start_time": "2020-05-17T16:03:43.748966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2647"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T16:06:39.751637Z",
     "start_time": "2020-05-17T16:06:39.533848Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000100039X', 8630, 0.3066740979538097),\n",
       " ('0002007770', 226, 0.32823697601367985),\n",
       " ('0002051850', 3940, 0.2881340682331206),\n",
       " ('0002219417', 2859, 0.4929340216048414),\n",
       " ('000222383X', 8086, 0.4170779150833703)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain the mapping of each inner id to raw id for every book\n",
    "item_baselines=[]\n",
    "\n",
    "for item in np.unique(df.asin):\n",
    "    item_baselines.append((item, trainset_full.to_inner_iid(item), algo.bi[trainset_full.to_inner_iid(item)]))\n",
    "\n",
    "item_baselines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T16:09:38.376548Z",
     "start_time": "2020-05-17T16:09:38.326023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10982"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T16:49:17.499049Z",
     "start_time": "2020-05-17T16:49:17.464440Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert the matrix into dataframe with the correct reviewerId and asins on the rows and columns\n",
    "pred_matrix_df = pd.DataFrame(pred_matrix, index = [x for x,y,z in sorted(user_baselines, key=lambda x:x[1])], \n",
    "                         columns = [x for x,y,z in sorted(item_baselines, key=lambda x:x[1])])\n",
    "\n",
    "#Make sure to cap the rating scale appropriately\n",
    "pred_matrix_df[pred_matrix_df>5] = 5\n",
    "pred_matrix_df[pred_matrix_df<1] = 1\n",
    "\n",
    "#Save to csv to avoid computing again\n",
    "pred_matrix_df.to_csv('/../../../pred_matrix_svd.csv.gz', \n",
    "                    index = True, header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T17:30:38.562865Z",
     "start_time": "2020-05-17T17:30:37.954611Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the details of the algorithm using the Surprise dump method to avoid refitting\n",
    "sur.dump.dump('/../../../svd_dump_file', algo=algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the top N recommendations, calculate the impact of the model and get a visual example, use the recommender_functions script and code from BaselineOnly or basic recommender system notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a recommender system using KNNBaseline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "All the relevant dataframes have already been loaded in and the data is in the format required for Surprise already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:20:09.516948Z",
     "start_time": "2020-06-03T22:20:09.509344Z"
    }
   },
   "outputs": [],
   "source": [
    "#Best options after gridsearching\n",
    "bsl_options = {'method': 'als',\n",
    "              'reg_i': 5, \n",
    "              'reg_u': 10,\n",
    "              'n_epochs': 15}\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 90, \n",
    "               'user_based': False}\n",
    "\n",
    "algo = sur.KNNBaseline(random_state=1,\n",
    "                       k=50,\n",
    "                       min_k=2, \n",
    "                       sim_options=sim_options,\n",
    "                       bsl_options = bsl_options\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:20:18.185772Z",
     "start_time": "2020-06-03T22:20:17.897716Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246294\n",
      "27367\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data in train and test set\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "#shuffle ratings if you want\n",
    "np.random.seed(1)\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "\n",
    "#section the data into training set and test set\n",
    "threshold = int(.9 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "print(len(A_raw_ratings))\n",
    "print(len(B_raw_ratings))\n",
    "\n",
    "#make the raw ratings contain only the training set\n",
    "data.raw_ratings = A_raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:21:14.889590Z",
     "start_time": "2020-06-03T22:20:26.849558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x1a456d2b10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Built a trainset out the training set\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:22:17.891399Z",
     "start_time": "2020-06-03T22:21:19.934108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score    RMSE: 0.1561\n",
      "0.15614119136214205\n"
     ]
    }
   ],
   "source": [
    "# Compute score on training set\n",
    "trainset_build = trainset.build_testset()\n",
    "predictions_train = algo.test(trainset_build)\n",
    "\n",
    "print('Training score ', end='   ')\n",
    "print(sur.accuracy.rmse(predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T22:22:27.033190Z",
     "start_time": "2020-06-03T22:22:20.404218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score (rated items)  RMSE: 0.8597\n",
      "0.8596883747472939\n"
     ]
    }
   ],
   "source": [
    "# Compute score on rated test set\n",
    "testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "predictions_test = algo.test(testset)\n",
    "print('Test score (rated items) ', end=' ')\n",
    "print(sur.accuracy.rmse(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the user matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the user-item prediction matrix for a KNNBaseline model is not as straightforward as the matrix factorisation or basic models. Therefore, we can use the Surprise method for generating all the unknown ratings and get this into a matrix format. The code below shows you how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.raw_ratings = raw_ratings\n",
    "\n",
    "#Built a trainset using the full data\n",
    "trainset_full = data.build_full_trainset()\n",
    "algo.fit(trainset_full)\n",
    "\n",
    "# Compute score on training set\n",
    "trainset_full_build = trainset_full.build_testset()\n",
    "predictions_full_train = algo.test(trainset_full_build)\n",
    "\n",
    "print('Training score ', end='   ')\n",
    "print(sur.accuracy.rmse(predictions_full_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the algo\n",
    "sur.dump.dump('/../../../KNNBaseline_dump_file', algo=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the whole list for all pairs of ratings not in there\n",
    "no_ratings = trainset_full.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large dataset so we need to iteratively create files that we can store the data at intermediate stages\n",
    "\n",
    "for chunk in range(0, 28800000, 100000):\n",
    "    predictions_no_ratings = algo.test(no_ratings[chunk:(chunk+100000)])\n",
    "    sur.dump.dump(f'/../../../KNNBaseline_dump_file_{chunk+100000}',\n",
    "              predictions = [predictions_no_ratings])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
